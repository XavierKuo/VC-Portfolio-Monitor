# ==========================================================
# main.py (Ver 5.6 - å®Œæ•´æ•´åˆç‰ˆ)
# é‚è¼¯ä¾†æº: Colab Ver 5.3
# ç’°å¢ƒé©é…: GitHub Actions Secrets
# ==========================================================
import requests
import json
import gspread
import time
import sys
import os
from oauth2client.service_account import ServiceAccountCredentials
from datetime import datetime, timedelta

# ===========================
# 1. ç’°å¢ƒè®Šæ•¸èˆ‡å…¨åŸŸè¨­å®š
# ===========================

# å¾ GitHub Secrets è®€å– Keys (å¦‚æœè®€ä¸åˆ°å‰‡ç‚º None)
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
SERPER_API_KEY = os.environ.get("SERPER_API_KEY")
TELEGRAM_BOT_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN")
TELEGRAM_CHAT_ID = os.environ.get("TELEGRAM_CHAT_ID")

# æª”æ¡ˆåç¨± (å¿…é ˆèˆ‡ Google Sheet ä¸€è‡´)
SHEET_NAME = "VC_Portfolio_Config"

# è™•ç† Google JSON
# GitHub Secret å­˜çš„æ˜¯å­—ä¸²ï¼Œé€™è£¡å¿…é ˆè½‰å› Python å­—å…¸
google_json_str = os.environ.get("GOOGLE_JSON", "{}")
try:
    GOOGLE_CREDS_JSON = json.loads(google_json_str)
except json.JSONDecodeError:
    print("âŒ éŒ¯èª¤: GOOGLE_JSON æ ¼å¼ä¸æ­£ç¢ºï¼Œè«‹ç¢ºä¿è²¼ä¸Šçš„æ˜¯ç´” JSON å…§å®¹ã€‚")
    GOOGLE_CREDS_JSON = {}

# å…¨åŸŸè®Šæ•¸å®¹å™¨
PORTFOLIO_CONFIG = {}
MEDIA_SOURCES = {}
GLOBAL_SOCIAL_SITES = []
REGIONS = {
    "TW": {"hl": "zh-TW", "gl": "tw", "name": "å°ç£"},
    "JP": {"hl": "ja", "gl": "jp", "name": "æ—¥æœ¬"},
    "US": {"hl": "en", "gl": "us", "name": "ç¾åœ‹"},
}

# ===========================
# 2. æ ¸å¿ƒåŠŸèƒ½å‡½å¼
# ===========================

def send_telegram_message(message):
    """ç™¼é€ Telegram è¨Šæ¯ (å«éŒ¯èª¤è¨ºæ–·)"""
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID:
        print("âš ï¸ Telegram Token æœªè¨­å®šï¼Œè·³éç™¼é€ã€‚")
        return

    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    max_length = 4000
    parts = [message[i:i+max_length] for i in range(0, len(message), max_length)]
    
    for part in parts:
        payload = {
            "chat_id": TELEGRAM_CHAT_ID,
            "text": part,
            "parse_mode": "Markdown",
            "disable_web_page_preview": True
        }
        try:
            response = requests.post(url, json=payload)
            if response.status_code != 200:
                print(f"âŒ Telegram API éŒ¯èª¤ï¼ç‹€æ…‹ç¢¼: {response.status_code}")
                print(f"   åŸå› : {response.text}")
            time.sleep(1)
        except Exception as e:
            print(f"âŒ Telegram ç™¼é€å¤±æ•—: {e}")

def load_all_config_from_sheets():
    """å¾ Google Sheet è®€å–æ‰€æœ‰é…ç½® (å®Œæ•´é‚è¼¯)"""
    global PORTFOLIO_CONFIG, MEDIA_SOURCES, GLOBAL_SOCIAL_SITES
    
    try:
        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        
        if not GOOGLE_CREDS_JSON:
            print("âŒ éŒ¯èª¤: GOOGLE_JSON ç‚ºç©ºï¼Œç„¡æ³•é€£ç·šã€‚")
            return False

        # ä½¿ç”¨ oauth2client é€²è¡Œèªè­‰ (èˆ‡ Colab é‚è¼¯ä¸€è‡´)
        creds = ServiceAccountCredentials.from_json_keyfile_dict(GOOGLE_CREDS_JSON, scope)
        client = gspread.authorize(creds)
        
        # é–‹å•Ÿè©¦ç®—è¡¨
        spreadsheet = client.open(SHEET_NAME)
        print(f"âœ… æˆåŠŸé€£ç·š Google Sheet: {SHEET_NAME}")
        
        # 1. è®€å– Portfolio
        portfolio_sheet = spreadsheet.worksheet("Portfolio")
        portfolio_records = portfolio_sheet.get_all_records()
        
        PORTFOLIO_CONFIG = {}
        for row in portfolio_records:
            company = row.get('Company')
            if not company: continue
            
            regions_str = row.get('Regions', 'TW')
            regions = [r.strip() for r in regions_str.split(',') if r.strip() in REGIONS]
            
            keywords_str = row.get('Keywords', company)
            keywords = [k.strip() for k in keywords_str.split(',') if k.strip()]
            
            PORTFOLIO_CONFIG[company] = {"regions": regions, "keywords": keywords}
        print(f"âœ… æˆåŠŸè¼‰å…¥ {len(PORTFOLIO_CONFIG)} é–“ Portfolio è¨­å®šã€‚")

        # 2. è®€å– Media Sources
        try:
            media_sheet = spreadsheet.worksheet("Media_Sources")
            media_records = media_sheet.get_all_records()
            MEDIA_SOURCES = {}
            for row in media_records:
                code = row.get('Region', '').upper()
                sites_str = row.get('Sites', '')
                sites = [s.strip() for s in sites_str.split(',') if s.strip()]
                if code and sites:
                    MEDIA_SOURCES[code] = sites
            print(f"âœ… æˆåŠŸè¼‰å…¥ {len(MEDIA_SOURCES)} å€‹åœ°å€åª’é«”é…ç½®ã€‚")
        except gspread.WorksheetNotFound:
             print("âš ï¸ è­¦å‘Š: æ‰¾ä¸åˆ° 'Media_Sources' åˆ†é ï¼Œå°‡ä½¿ç”¨é è¨­å€¼ã€‚")

        # 3. è®€å– Global Settings
        try:
            global_sheet = spreadsheet.worksheet("Global_Settings")
            global_records = global_sheet.get_all_records()
            global_settings = {}
            for row in global_records:
                global_settings[row.get('Setting_Name')] = row.get('Value')
            
            social_sites_str = global_settings.get('GLOBAL_SOCIAL_SITES', 'site:linkedin.com')
            GLOBAL_SOCIAL_SITES = [s.strip() for s in social_sites_str.split(',') if s.strip()]
            print(f"âœ… æˆåŠŸè¼‰å…¥å…¨åŸŸç¤¾ç¾¤ç®¡é“ã€‚")
        except gspread.WorksheetNotFound:
             print("âš ï¸ è­¦å‘Š: æ‰¾ä¸åˆ° 'Global_Settings' åˆ†é ï¼Œå°‡ä½¿ç”¨é è¨­å€¼ã€‚")
             GLOBAL_SOCIAL_SITES = ["site:linkedin.com"]
        
        return True
    
    except gspread.exceptions.SpreadsheetNotFound:
        print(f"âŒ åš´é‡éŒ¯èª¤: æ‰¾ä¸åˆ°åç‚º '{SHEET_NAME}' çš„ Google Sheetã€‚")
        print("ğŸ’¡ è«‹ç¢ºèªï¼š1. GitHub Secret JSON æ­£ç¢º 2. Service Account å·²åŠ å…¥ç·¨è¼¯è€… 3. æª”åå®Œå…¨ä¸€è‡´")
        return False
    except Exception as e:
        print(f"âŒ Google Sheet è®€å–ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {e}")
        return False

def search_google_news(query, hl="zh-TW", gl="tw"):
    """Serper API æœå°‹"""
    url = "https://google.serper.dev/search"
    payload = json.dumps({
        "q": query,
        "tbs": "qdr:w",
        "num": 15,
        "hl": hl,
        "gl": gl
    })
    headers = {'X-API-KEY': SERPER_API_KEY, 'Content-Type': 'application/json'}
    try:
        response = requests.request("POST", url, headers=headers, data=payload)
        return response.json()
    except Exception as e:
        return {"error": str(e)}

def analyze_with_gpt(company_name, all_search_results_list):
    """OpenAI åˆ†æ"""
    all_organic_results = []
    seen_links = set()
    
    for result_dict in all_search_results_list:
        if 'organic' in result_dict:
            for item in result_dict['organic']:
                link = item.get('link')
                if link and link not in seen_links:
                    all_organic_results.append(item)
                    seen_links.add(link)
    
    if not all_organic_results: return None

    today = datetime.now()
    seven_days_ago = today - timedelta(days=7)
    today_str = today.strftime("%Y-%m-%d")
    seven_days_ago_str = seven_days_ago.strftime("%Y-%m-%d")

    news_text = ""
    for item in all_organic_results[:20]:
        title = item.get('title', 'No Title')
        snippet = item.get('snippet', 'No Snippet')
        link = item.get('link', '')
        date = item.get('date', 'Unknown Date')
        news_text += f"- [æ™‚é–“æ¨™è¨˜: {date}] {title} ({link}): {snippet}\n"

    prompt = f"""
    ä½ æ˜¯ä¸€ä½åš´è¬¹çš„ VC æŠ•è³‡åˆ†æå¸«ã€‚ä»Šå¤©æ˜¯ï¼š{today_str}ã€‚
    ä»»å‹™ï¼šå¯©æŸ¥ã€Œ{company_name}ã€å½™æ•´å¾Œçš„å…¨çƒæœå°‹çµæœã€‚

    ã€åš´æ ¼æ™‚é–“éæ¿¾ã€‘
    åƒ…æ¥å—ç™¼ç”Ÿåœ¨ **{seven_days_ago_str} è‡³ {today_str}** ä¹‹é–“çš„æ–°èã€‚
    è‹¥æ™‚é–“æ¨™è¨˜é¡¯ç¤º "1 year ago", "2023" ç­‰èˆŠèï¼Œ**çµ•å°æ’é™¤**ã€‚
    è‹¥ç„¡æ–°æ¶ˆæ¯ï¼Œå›ç­”ã€Œç„¡é‡å¤§æ¶ˆæ¯ã€ã€‚

    ã€é«˜åƒ¹å€¼è¨Šè™Ÿã€‘
    1. ğŸš¨ å…¬é—œå±æ©Ÿ/ç¤¾ç¾¤ç‚ä¸Š
    2. ğŸ’° å‹Ÿè³‡/ä½µè³¼/IPO
    3. ğŸš€ ç”¢å“é‡‹å‡º/é‡å¤§æ›´æ–°
    4. ğŸ“¢ é‡å¤§å“ç‰Œæ´»å‹•/å¹´åº¦å±•æœƒ
    5. ğŸ¤ é—œéµåˆä½œ
    6. ğŸ‘¤ é«˜å±¤äººäº‹ç•°å‹•

    ã€å…§å®¹ç¿»è­¯ã€‘
    è‹¥ç‚ºå¤–æ–‡ï¼Œè«‹ç¿»è­¯ç‚ºç¹é«”ä¸­æ–‡ã€‚

    ã€è³‡æ–™åº«ã€‘
    {news_text}

    ã€è¼¸å‡ºæ ¼å¼ã€‘
    è‹¥ç„¡æ¶ˆæ¯ï¼Œå›ç­”ã€Œç„¡é‡å¤§æ¶ˆæ¯ã€ã€‚
    è‹¥æœ‰ï¼Œä¾åºè¼¸å‡ºï¼š
    - **ã€é¡åˆ¥ | è·¨åœ‹çµ±ä¸€æ¨™ç±¤ã€‘æ¨™é¡Œ**
    - **äº‹ä»¶æ‘˜è¦** (100å­—å…§)
    - **ğŸ” ä¾æ“šä¾†æº** (å«é€£çµ)
    """

    url = "https://api.openai.com/v1/chat/completions"
    headers = {"Authorization": f"Bearer {OPENAI_API_KEY}", "Content-Type": "application/json"}
    data = {"model": "gpt-4o", "messages": [{"role": "user", "content": prompt}], "temperature": 0.0}
    
    try:
        response = requests.post(url, headers=headers, json=data)
        result = response.json()
        if 'error' in result: return f"API Error: {result['error']['message']}"
        content = result['choices'][0]['message']['content']
        if "ç„¡é‡å¤§æ¶ˆæ¯" in content: return None
        return content
    except Exception as e:
        return f"ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {str(e)}"

# ===========================
# 3. ä¸»ç¨‹å¼åŸ·è¡Œé‚è¼¯
# ===========================
if __name__ == "__main__":
    print("ğŸš€ é–‹å§‹åŸ·è¡Œ VC Portfolio Tracker (GitHub Actions Mode)...\n")

    # 1. è¼‰å…¥é…ç½®
    if not load_all_config_from_sheets():
        error_msg = f"âŒ åš´é‡éŒ¯èª¤: ç„¡æ³•å¾ Google Sheet è¼‰å…¥é…ç½®ã€‚æª¢æŸ¥ GitHub Secrets å’Œ Sheet å…±ç”¨æ¬Šé™ã€‚"
        print(error_msg)
        send_telegram_message(error_msg)
        sys.exit(1)

    final_report_sections = []
    stats = {
        "total_tracked": len(PORTFOLIO_CONFIG),
        "news_found": 0,
        "regions_scanned": set(),
        "time_start": datetime.now(),
    }
    successful_scans = 0 

    # 2. åŸ·è¡Œæƒæ
    for company_name, config in PORTFOLIO_CONFIG.items():
        keywords = config["keywords"]
        target_regions = config["regions"]
        
        print(f"\n--- åˆ†æ: {company_name} ---")
        
        all_search_results = []
        all_search_terms = keywords + GLOBAL_SOCIAL_SITES
        
        for region_code in target_regions:
            if region_code not in REGIONS: continue
            
            stats["regions_scanned"].add(region_code)
            region_info = REGIONS[region_code]
            regional_media = MEDIA_SOURCES.get(region_code, [])
            
            combined_query = " OR ".join(all_search_terms + regional_media)
            
            search_res = search_google_news(combined_query, hl=region_info["hl"], gl=region_info["gl"])
            
            if "error" in search_res:
                print(f"   âŒ {region_info['name']} æœå°‹éŒ¯èª¤: {search_res['error']}")
            else:
                all_search_results.append(search_res)
                successful_scans += 1

        if all_search_results:
            print("   ğŸ¤– æ­£åœ¨é€²è¡Œ AI ç¶œåˆåˆ†æ...")
            analysis = analyze_with_gpt(company_name, all_search_results)
            
            if analysis and "ç„¡é‡å¤§æ¶ˆæ¯" not in analysis and "API Error" not in analysis:
                print(f"   âœ… {company_name} ç™¼ç¾æ¶ˆæ¯")
                stats["news_found"] += 1
                final_report_sections.append(f"*{company_name}*\n{analysis}\n")
            else:
                print(f"   ğŸ’¤ {company_name} ç„¡é‡å¤§æ¶ˆæ¯")
        
        time.sleep(1)

    # 3. ç”Ÿæˆå ±å‘Š
    time_taken = datetime.now() - stats["time_start"]
    total_expected = stats['total_tracked'] * len(stats['regions_scanned']) if stats['regions_scanned'] else 1
    success_rate = f"{successful_scans / total_expected * 100:.0f}%" if total_expected > 0 else "0%"

    header = f"ğŸ¤– *Daily Portfolio Monitor*\nğŸ“… Date: {datetime.now().strftime('%Y-%m-%d')}\n"
    stats_block = (
        "\nğŸ“Š *Summary Statistics:*\n"
        f"â€¢ Companies: {stats['total_tracked']}\n"
        f"â€¢ Updates: {stats['news_found']}\n"
        f"â€¢ Success Rate: {success_rate}\n"
        f"â€¢ Time: {str(time_taken).split('.')[0]}\n\n"
        "ğŸ“ *Highlights:*\n" + "-"*15 + "\n"
    )

    if final_report_sections:
        body = "\n".join(final_report_sections)
        full_report = header + stats_block + body
    else:
        full_report = header + stats_block + "æœ¬é€± Portfolio å¹³éœç„¡æ³¢ã€‚"

    print("\næ­£åœ¨ç™¼é€ Telegram å ±å‘Š...")
    send_telegram_message(full_report)
    print("âœ… å®Œæˆï¼")
