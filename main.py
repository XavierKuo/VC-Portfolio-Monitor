# ==========================================================
# main.py (Ver 7.2 - GitHub Production)
# åŠŸèƒ½ï¼š
# 1. é›™é‡æœå°‹æ©Ÿåˆ¶ (Targeted Media -> Fallback Wide Search)
# 2. AI åš´æ ¼äº‹å¯¦æ‘˜è¦ + å…­å¤§è¨Šè™Ÿåˆ†é¡
# 3. Vibe VC é¢¨æ ¼å ±å‘Š (ç§»é™¤é‡è¤‡æ¨™é¡Œï¼Œå„ªåŒ–æ’ç‰ˆ)
# ==========================================================
import requests
import json
import gspread
import time
import sys
import os
from oauth2client.service_account import ServiceAccountCredentials
from datetime import datetime, timedelta

# ===========================
# 1. ç’°å¢ƒè®Šæ•¸èˆ‡å…¨åŸŸè¨­å®š
# ===========================

# GitHub Secrets è®€å–
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
SERPER_API_KEY = os.environ.get("SERPER_API_KEY")
TELEGRAM_BOT_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN")
TELEGRAM_CHAT_ID = os.environ.get("TELEGRAM_CHAT_ID")

SHEET_NAME = "VC_Portfolio_Config"

# è™•ç† Google JSON (å¾ GitHub Secret å­—ä¸²è½‰ç‚º JSON ç‰©ä»¶)
google_json_str = os.environ.get("GOOGLE_JSON", "{}")
try:
    GOOGLE_CREDS_JSON = json.loads(google_json_str)
except json.JSONDecodeError:
    print("âŒ éŒ¯èª¤: GOOGLE_JSON æ ¼å¼ä¸æ­£ç¢ºã€‚")
    GOOGLE_CREDS_JSON = {}

# å…¨åŸŸè®Šæ•¸åˆå§‹åŒ–
PORTFOLIO_CONFIG = {}
MEDIA_SOURCES = {}
GLOBAL_SOCIAL_SITES = []
REGIONS = {
    "TW": {"hl": "zh-TW", "gl": "tw", "name": "TW"},
    "JP": {"hl": "ja", "gl": "jp", "name": "JP"},
    "US": {"hl": "en", "gl": "us", "name": "US"},
}

# ===========================
# 2. æ ¸å¿ƒåŠŸèƒ½å‡½å¼å€
# ===========================

# --- 1. Telegram ç™¼é€å‡½å¼ ---
def send_telegram_message(message):
    """ç™¼é€ Telegram è¨Šæ¯"""
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID:
        print("âš ï¸ Telegram Token æœªè¨­å®šï¼Œè·³éç™¼é€ã€‚")
        return

    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    
    # Telegram è¨Šæ¯é•·åº¦é™åˆ¶è™•ç† (4096 char limit safeguard)
    max_length = 3800 
    parts = [message[i:i+max_length] for i in range(0, len(message), max_length)]
    
    for part in parts:
        payload = {
            "chat_id": TELEGRAM_CHAT_ID,
            "text": part,
            "parse_mode": "Markdown",
            "disable_web_page_preview": True
        }
        try:
            response = requests.post(url, json=payload)
            if response.status_code != 200:
                print(f"âŒ Telegram API Error: {response.text}")
            time.sleep(1)
        except Exception as e:
            print(f"âŒ Telegram ç™¼é€å¤±æ•—: {e}")

# --- 2. Google Sheet è®€å–å‡½å¼ ---
def load_all_config_from_sheets():
    """å¾ Google Sheet è®€å–æ‰€æœ‰é…ç½®"""
    global PORTFOLIO_CONFIG, MEDIA_SOURCES, GLOBAL_SOCIAL_SITES
    
    try:
        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        
        if not GOOGLE_CREDS_JSON:
            print("âŒ éŒ¯èª¤: GOOGLE_CREDS_JSON ç‚ºç©ºã€‚")
            return False

        creds = ServiceAccountCredentials.from_json_keyfile_dict(GOOGLE_CREDS_JSON, scope)
        client = gspread.authorize(creds)
        spreadsheet = client.open(SHEET_NAME)
        
        # 1. Portfolio
        portfolio_sheet = spreadsheet.worksheet("Portfolio")
        portfolio_records = portfolio_sheet.get_all_records()
        
        PORTFOLIO_CONFIG = {}
        for row in portfolio_records:
            company = row.get('Company')
            if not company: continue
            
            regions_str = row.get('Regions', 'TW')
            regions = [r.strip() for r in regions_str.split(',') if r.strip() in REGIONS]
            
            keywords_str = row.get('Keywords', company)
            keywords = [k.strip() for k in keywords_str.split(',') if k.strip()]
            
            PORTFOLIO_CONFIG[company] = {"regions": regions, "keywords": keywords}
        print(f"âœ… æˆåŠŸè¼‰å…¥ {len(PORTFOLIO_CONFIG)} é–“ Portfolioã€‚")

        # 2. Media Sources
        try:
            media_sheet = spreadsheet.worksheet("Media_Sources")
            media_records = media_sheet.get_all_records()
            MEDIA_SOURCES = {}
            for row in media_records:
                code = row.get('Region', '').upper()
                sites_str = row.get('Sites', '')
                sites = [s.strip() for s in sites_str.split(',') if s.strip()]
                if code and sites:
                    MEDIA_SOURCES[code] = sites
        except gspread.WorksheetNotFound:
             print("âš ï¸ ç„¡ Media_Sources åˆ†é ï¼Œä½¿ç”¨é è¨­å€¼ã€‚")

        # 3. Global Settings
        try:
            global_sheet = spreadsheet.worksheet("Global_Settings")
            global_records = global_sheet.get_all_records()
            global_settings = {}
            for row in global_records:
                global_settings[row.get('Setting_Name')] = row.get('Value')
            
            social_sites_str = global_settings.get('GLOBAL_SOCIAL_SITES', 'site:linkedin.com')
            GLOBAL_SOCIAL_SITES = [s.strip() for s in social_sites_str.split(',') if s.strip()]
        except gspread.WorksheetNotFound:
             GLOBAL_SOCIAL_SITES = ["site:linkedin.com"]
        
        return True
    except Exception as e:
        print(f"âŒ Google Sheet è®€å–éŒ¯èª¤: {e}")
        return False

# --- 3. æœå°‹å‡½å¼ ---
def search_google_news(query, hl="zh-TW", gl="tw"):
    """Serper API æœå°‹"""
    url = "https://google.serper.dev/search"
    payload = json.dumps({
        "q": query,
        "tbs": "qdr:w", # é™åˆ¶éå»ä¸€é€±
        "num": 25,      # å–å‰ 25 ç­†ç¢ºä¿è¦†è“‹ç‡
        "hl": hl,
        "gl": gl
    })
    headers = {'X-API-KEY': SERPER_API_KEY, 'Content-Type': 'application/json'}
    try:
        response = requests.request("POST", url, headers=headers, data=payload)
        return response.json()
    except Exception as e:
        return {"error": str(e)}

# --- 4. AI åˆ†æå‡½å¼ (Ver 7.1 - è¨Šè™Ÿåˆ†é¡èˆ‡æ ¼å¼ç¾åŒ–ç‰ˆ) ---
def analyze_with_gpt(company_name, all_search_results_list):
    OPENAI_MODEL_NAME = "gpt-4o" 
    all_items = []
    seen = set()
    for res in all_search_results_list:
        items = res.get('organic', [])
        for item in items:
            if item.get('link') not in seen:
                all_items.append(item)
                seen.add(item.get('link'))
    
    if not all_items: return None

    today_str = datetime.now().strftime("%Y-%m-%d")
    news_context = ""
    # æä¾›å‰ 20 ç­†è³‡æ–™çµ¦ AIï¼Œå¢åŠ æ·±åº¦
    for i in all_items[:20]:
        news_context += f"- [Source: {i.get('source', 'Unknown')}] [Title: {i.get('title')}] [Date: {i.get('date', 'Recent')}]\n  Snippet: {i.get('snippet')}\n  Link: {i.get('link')}\n"

    prompt = f"""
    Role: You are a Senior Venture Capitalist; 
    Date: Today is {today_str}; 
    Missionï¼šåˆ†æã€Œ{company_name}ã€éå» 7 å¤©çš„é‡è¦å‹•æ…‹ï¼Œä¸¦éµå®ˆä»¥ä¸‹çš„æ¶ˆæ¯åˆ†é¡èˆ‡è¼¸å‡ºæ ¼å¼ã€‚

    ã€High Value Signals & Categorizationã€‘
    è«‹å°‡æ–°èåˆ†é¡ç‚ºä»¥ä¸‹ 6 ç¨®è‹±æ–‡æ¨™ç±¤ï¼š
    1. [ğŸš¨ CRISIS] (å…¬é—œå±æ©Ÿã€æ³•å¾‹è¨´è¨Ÿã€è² é¢çˆ­è­°)
    2. [ğŸ’° FUNDING] (å‹Ÿè³‡å‹•æ…‹ã€ä½µè³¼ M&Aã€ä¸Šå¸‚ IPO)
    3. [ğŸš€ PRODUCT] (æ–°ç”¢å“ç™¼å¸ƒã€é‡å¤§åŠŸèƒ½æ›´æ–°)
    4. [ğŸ“¢ EVENT] (å“ç‰Œé‡å¤§æ´»å‹•ã€å¤§å‹å±•è¦½)
    5. [ğŸ¤ PARTNERSHIP] (ç­–ç•¥è¯ç›Ÿã€é‡å¤§å®¢æˆ¶ç°½ç´„)
    6. [ğŸ‘¤ PEOPLE] (æ ¸å¿ƒé«˜å±¤ C-Level è®Šå‹•)

    ã€æ ¸å¿ƒæŒ‡ä»¤ï¼šç¿»è­¯èˆ‡å“è³ªã€‘
    1. **å…¨ç¹é«”ä¸­æ–‡è¼¸å‡º**ï¼šç„¡è«–åŸå§‹è³‡æ–™æ˜¯æ—¥æ–‡æˆ–è‹±æ–‡ï¼Œè¼¸å‡ºå…§å®¹ï¼ˆå«æ¨™é¡Œèˆ‡æ‘˜è¦ï¼‰å¿…é ˆç¿»è­¯ç‚ºã€Œç¹é«”ä¸­æ–‡ã€ã€‚
    2. **ç¢ºä¿æ‘˜è¦æ·±åº¦**ï¼šæ‘˜è¦æ‡‰åŒ…å«å…·é«”çš„äº‹å¯¦ç´°ç¯€ï¼Œä¾‹å¦‚ã€Œã€Œå…·é«”åˆä½œå°è±¡ã€æˆ–ã€Œç‡Ÿé‹ã€è²¡å‹™æ•¸æ“šã€ã€‚ä¸æ‡‰ç‚ºäº†ç°¡çŸ­è€Œå¿½ç•¥é—œéµåè©ã€‚
    3. **åš´æ ¼äº‹å¯¦éæ¿¾**ï¼šåƒ…æè¿°ç™¼ç”Ÿçš„äº‹ä»¶ï¼Œåš´ç¦ AI è‡ªè¡Œç™¼æ®é æ¸¬æˆ–æ¨è«–æ„è¦‹ã€‚

    ã€è¼¸å‡ºæ ¼å¼è¦ç¯„ã€‘
    1. **Company Header**ï¼šç¬¬ä¸€è¡Œå¿…é ˆæ˜¯ "ğŸ¢ **{company_name}**" å…¬å¸åç¨±éœ€ç²—é«”ä¸”å¾Œæ–¹ç©ºå…©è¡Œã€‚
    2. **æ•¸é‡é™åˆ¶**ï¼šæ¯å®¶å…¬å¸æœ€å¤šæä¾› 3 å€‹æœ€é‡è¦çš„æ›´æ–°ã€‚
    3. **æ¢ç›®é–“éš”**ï¼šä¸åŒæ¶ˆæ¯æ¢ç›®ä¹‹é–“è«‹ç©ºä¸€è¡Œã€‚
    4. **æ¨™é¡Œæ ¼å¼**ï¼š**æ¨™ç±¤ | ç¹é«”ä¸­æ–‡æ¨™é¡Œ**ã€‚
    5. **å…§å®¹æ ¼å¼**ï¼šæ‘˜è¦å¾Œæ–¹æ›è¡Œæ¥ "ğŸ” Ref."ã€‚
    6. **é€£çµæ ¼å¼**ï¼šä½¿ç”¨ Markdown `[ç¶²ç«™åç¨± | åŸå§‹æ¨™é¡Œ](åŸå§‹é€£çµ)`ã€‚

    ã€è¼¸å‡ºç¯„ä¾‹åƒè€ƒã€‘
    ğŸ¢ **SpaceX**

    [ğŸ’° FUNDING] | SpaceX æˆåŠŸç²å¾— NASA ç™»æœˆè¨ˆåŠƒæ–°åˆç´„
    SpaceX æœ¬é€±æ­£å¼å–å¾— NASA åƒ¹å€¼ 2 å„„ç¾å…ƒçš„åˆç´„ï¼Œå°‡å°ˆç”¨æ–¼é–‹ç™¼æ˜Ÿè‰¦ç³»çµ±çš„è‘—é™¸æŠ€è¡“ã€‚
    ğŸ” Ref. [Reuters | SpaceX clinches NASA contract](https://reuters.com/...)

    è‹¥å®Œå…¨ç„¡ç¬¦åˆä¸Šè¿°é¡åˆ¥çš„æ–°èï¼Œè«‹å›è¦†ï¼šNo huge updates.
    
    è³‡æ–™åº«å…§å®¹ï¼š
    {news_context}
    """
    try:
        data = {"model": OPENAI_MODEL_NAME, "messages": [{"role": "user", "content": prompt}], "temperature": 0}
        res = requests.post("https://api.openai.com/v1/chat/completions", 
                            headers={"Authorization": f"Bearer {OPENAI_API_KEY}"}, json=data).json()
        
        if 'error' in res:
            print(f"âš ï¸ OpenAI API Error: {res['error']}")
            return None

        content = res['choices'][0]['message']['content']
        
        if "No huge updates" in content:
            return None
            
        return content
    except Exception as e:
        print(f"AI åˆ†æå‡ºéŒ¯: {e}")
        return None

# ===========================
# 3. ä¸»ç¨‹å¼åŸ·è¡Œé‚è¼¯å€ (Ver 7.2 - GitHub Actions Mode)
# ===========================
if __name__ == "__main__":
    print("ğŸš€ Starting VC Portfolio Tracker (GitHub Actions Mode)...")

    # æª¢æŸ¥æ˜¯å¦èƒ½æˆåŠŸè¼‰å…¥é…ç½®
    if not load_all_config_from_sheets():
        error_msg = f"âŒ åš´é‡éŒ¯èª¤: ç„¡æ³•å¾ Google Sheet è¼‰å…¥é…ç½®ã€‚"
        print(error_msg)
        send_telegram_message(error_msg)
        sys.exit(1)

    final_report_sections = []
    stats = {
        "total_tracked": len(PORTFOLIO_CONFIG),
        "news_found": 0,
        "regions_scanned": set(), 
        "time_start": datetime.now()
    }

    # åŸ·è¡Œæƒæ
    for company, cfg in PORTFOLIO_CONFIG.items():
        print(f"ğŸ” Scanning: {company}...")
        
        keywords_query = "(" + " OR ".join(cfg['keywords']) + ")"
        all_res = []
        total_items_found = 0
        
        for r_code in cfg['regions']:
            if r_code not in REGIONS: continue
            stats["regions_scanned"].add(REGIONS[r_code]['name'])
            
            # --- ç¬¬ä¸€éšæ®µï¼šé™å®šåª’é«”æœå°‹ (Targeted Search) ---
            media_list = MEDIA_SOURCES.get(r_code, []) + GLOBAL_SOCIAL_SITES
            media_list = [m.strip() for m in media_list if m.strip()]
            media_filter = "(" + " OR ".join(media_list[:8]) + ")" if media_list else ""
            
            full_query = f"{keywords_query} {media_filter}".strip()
            res = search_google_news(full_query, hl=REGIONS[r_code]['hl'], gl=REGIONS[r_code]['gl'])
            
            items = res.get('organic', [])
            
            # --- ç¬¬äºŒéšæ®µï¼šå‚™æ´æ©Ÿåˆ¶ (Fallback: Wide Search) ---
            # è‹¥é™å®šåª’é«”ç„¡çµæœï¼Œé‡å°è©²åœ°å€è£œè·‘ä¸€æ¬¡ã€Œå…¨ç¶²æœå°‹ã€
            if not items:
                print(f"   âš ï¸ Fallback to Wide Search for {company} in {r_code}...")
                wide_query = f"{keywords_query} latest news"
                res = search_google_news(wide_query, hl=REGIONS[r_code]['hl'], gl=REGIONS[r_code]['gl'])
                items = res.get('organic', [])
            
            if items:
                total_items_found += len(items)
                all_res.append(res)

        # --- AI åˆ†æéšæ®µ ---
        if total_items_found > 0:
            report = analyze_with_gpt(company, all_res)
            if report:
                print(f"   âœ… Update Found!")
                stats["news_found"] += 1
                # ç›´æ¥åŠ å…¥ AI ç”¢å‡ºçš„æ ¼å¼å…§å®¹ (å…§å« Company Header)
                final_report_sections.append(report)
            else:
                print(f"   ğŸ’¤ No significant update judged by AI")
        else:
            print(f"   ğŸ“­ No results found from any source")
        
        time.sleep(1) # é¿å… API Rate Limit

    # --- ç”Ÿæˆå ±å‘Š (Vibe VC Style) ---
    today_str = datetime.now().strftime('%Y-%m-%d')
    header = f"âœ¨ *Weekly Portfolio Update* ({today_str})\n\n"

    display_regions = ", ".join(stats["regions_scanned"]) if stats["regions_scanned"] else "None"
    
    stats_block = (
        "ğŸ“Š *Summary Statistics*\n"
        f"â€¢ Companies Tracked: `{stats['total_tracked']}`\n"
        f"â€¢ Important Updates: `{stats['news_found']}`\n"
        f"â€¢ Regions Scanned: {display_regions}\n\n"
        "ğŸ“ *Key Highlights*\n"
        "â”â”â”â”â”â”â”â”â”â”â”\n\n"
    )

    if final_report_sections:
        # ä½¿ç”¨é›™æ›è¡Œåˆ†éš”ä¸åŒå…¬å¸çš„å€å¡Š
        body = "\n\n".join(final_report_sections)
        full_report = header + stats_block + body
    else:
        full_report = header + stats_block + "_No major updates found this week._"

    print("\nğŸ“¤ Sending Telegram report...")
    send_telegram_message(full_report)
    print("âœ… Done!")
